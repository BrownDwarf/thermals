{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "## 3 - Overview of available files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to explore the Kepler/K2 telemetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the directory structure look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/\r\n",
      "├── AED\r\n",
      "│   ├── K2\r\n",
      "│   │   ├── attitude\r\n",
      "│   │   └── thermal\r\n",
      "│   └── Kepler\r\n",
      "│       ├── attitude\r\n",
      "│       └── thermal\r\n",
      "└── notAed\r\n",
      "    ├── K2\r\n",
      "    │   ├── attitude\r\n",
      "    │   │   ├── c0\r\n",
      "    │   │   │   ├── 2ndhalf\r\n",
      "    │   │   │   └── allgood\r\n",
      "    │   │   ├── c1\r\n",
      "    │   │   ├── c10b\r\n",
      "    │   │   ├── c11\r\n",
      "    │   │   ├── c12\r\n",
      "    │   │   ├── c13\r\n",
      "    │   │   ├── c14\r\n",
      "    │   │   ├── c15\r\n",
      "    │   │   ├── c16\r\n",
      "    │   │   ├── c17\r\n",
      "    │   │   ├── c18\r\n",
      "    │   │   ├── c19\r\n",
      "    │   │   ├── c2\r\n",
      "    │   │   ├── c3\r\n",
      "    │   │   ├── c4\r\n",
      "    │   │   ├── c5\r\n",
      "    │   │   ├── c6\r\n",
      "    │   │   ├── c7\r\n",
      "    │   │   ├── c8\r\n",
      "    │   │   ├── c9a\r\n",
      "    │   │   └── c9b\r\n",
      "    │   └── thermal\r\n",
      "    └── Kepler\r\n",
      "        ├── attitude\r\n",
      "        └── thermal\r\n",
      "\r\n",
      "37 directories\r\n"
     ]
    }
   ],
   "source": [
    "! tree -d ../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can collect and sort the text file names in preparation for reading the files programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files = glob.glob('../data/Aed/K2/thermal/*.txt')\n",
    "txt_files = natsorted(txt_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four distinct file types per campaign, identified by their suffixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BoardTemperatures',\n",
       " 'TelescopeTemperatureTH_2',\n",
       " 'TelescopeTemperatureTH_1',\n",
       " 'TelescopeTemperaturePED']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffixes = [strings.split('_', maxsplit=1)[-1].split('.')[0] for strings in txt_files]\n",
    "uniq_suffixes = list(set(suffixes))\n",
    "uniq_suffixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make dataframes for all of these.  The files do not all have the same time sampling, so we will gather the dataframes into a holder dictionary, rather than merge them into a single DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_dict = {'C0':0,'C1':1,'C2':2,'C3':3,'C4':4,'C5':5,'C6':6,'C7':7,'C8':8,'C9a':91,'C9b':92,'C10b':101,'C11a':111,'C11b':112,\n",
    "                 'C12':12,'C13':13,'C14':14,'C15':15,'C16':16,'C17':17,'C18':18,'C19':19}\n",
    "campaigns = list(campaign_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step takes about 10 seconds to read in all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.1 s, sys: 11.5 s, total: 47.6 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "holder = {suffix:pd.DataFrame() for suffix in uniq_suffixes}\n",
    "for suffix in uniq_suffixes:\n",
    "    holder[suffix] = pd.DataFrame()\n",
    "    for campaign in campaigns:\n",
    "        fn = '../data/AED/K2/thermal/{}_{}.txt'.format(campaign, suffix)\n",
    "        df = pd.read_csv(fn, skiprows=[0,1,2,3,4,6], sep='|')\n",
    "        df['campaign']=campaign_dict[campaign]\n",
    "        holder[suffix] = holder[suffix].append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dictionary entry contains a dataframe.  The dataframes have different time sampling, so we can't simply match on the time axis.  In a future notebook we will merge times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['BoardTemperatures', 'TelescopeTemperatureTH_2', 'TelescopeTemperatureTH_1', 'TelescopeTemperaturePED'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(holder['BoardTemperatures'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the various dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoardTemperatures: (1100448, 14) \n",
      "     >>>> ['MJD' 'LC' 'SC' 'PEDDRV1T' 'PEDACQ1T' 'PEDDRV2T' 'PEDACQ2T' 'PEDDRV3T'\n",
      " 'PEDACQ3T' 'PEDDRV4T' 'PEDACQ4T' 'PEDDRV5T' 'PEDACQ5T' 'campaign'] \n",
      "\n",
      "TelescopeTemperatureTH_2: (1121179, 8) \n",
      "     >>>> ['MJD' 'LC' 'SC' 'TH1SPIDT' 'TH2SPIDT' 'TH1TELET' 'TH2TELET' 'campaign'] \n",
      "\n",
      "TelescopeTemperatureTH_1: (1121182, 6) \n",
      "     >>>> ['MJD' 'LC' 'SC' 'TH1SCMNTT' 'TH2SCMNTT' 'campaign'] \n",
      "\n",
      "TelescopeTemperaturePED: (1100599, 13) \n",
      "     >>>> ['MJD' 'LC' 'SC' 'PEDCRRT1' 'PEDCRRT2' 'PEDCRRT3' 'PEDCRRT4' 'PEDPMAT1'\n",
      " 'PEDPMAT2' 'PEDPMAT3' 'PEDPMAT4' 'PEDTELMNTT1' 'campaign'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for suffix in uniq_suffixes:\n",
    "    print(\"{}: {} \\n\".format(suffix, holder[suffix].shape), \n",
    "          \"    >>>> {} \\n\".format(holder[suffix].columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the dataframes have over 1 million rows.  Wow!  Let's dig into these temperature data more closely in the next notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
